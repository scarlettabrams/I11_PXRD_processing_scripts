{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda25d24",
   "metadata": {},
   "source": [
    "# Fast Post Merging Baselining Data Processing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe0be1-0d22-4247-a733-c0f64f44e13a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Some adaptations from beth's pyFAI Muktibaselines script but overall the same "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b0579",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c987ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import pandas as pd        \n",
    "import math\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install pyFAI\n",
    "import pyFAI\n",
    "from pyFAI.gui import jupyter\n",
    "\n",
    "!{sys.executable} -m pip install pybaselines\n",
    "from pybaselines import Baseline\n",
    "from pybaselines.utils import gaussian\n",
    "\n",
    "pi = math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e0a33",
   "metadata": {},
   "source": [
    "# Load calibration file\n",
    "\n",
    "calibrated using pyFAI-calib2 tool\n",
    "\n",
    "pyFAI: https://pyfai.readthedocs.io/en/v2023.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ec700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the calibration .poni file \n",
    "calibration = pyFAI.load('D:/I11 Beamtime July/calib_kap.poni')  #('C:/poni/file/location/calibration.poni')\n",
    "calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c749adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mask for detector frame\n",
    "oneD_mask = np.load('D:/I11 Beamtime July/calib_kap_mask.npy') #(\"C:/mask/file/location/mask.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524449d",
   "metadata": {},
   "source": [
    "# Specify folder of frames to read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aba7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder of nxs files to read in\n",
    "\n",
    "collection_dir = \"D:/I11 Beamtime July/RAW_2D/Run_8_X2_0.5VF/\" #\"C:/collection/set/of/raw/nxs/files/location/\"\n",
    "run_id = \"Run_8_X2_0.5VF\"\n",
    "\n",
    "count = 0\n",
    "file_nxs = []\n",
    "\n",
    "# Count the number of .nxs files in directory\n",
    "for files in os.listdir(collection_dir):\n",
    "    filename = os.fsdecode(files)\n",
    "    if filename.endswith(\".nxs\"):\n",
    "        file_nxs.append(filename)\n",
    "        count += 1\n",
    "print('File count:', count)\n",
    "print(file_nxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19360b-3eb9-4583-ba1e-ed8d4dc419e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett adaptations - output directory made \n",
    "#make output directory \n",
    "processing_folder_dir = \"D:/I11 Beamtime July/RAW_2D/Run_8_X2_0.5VF/\"\n",
    "\n",
    "processing_folder = \"05_PostM_Baselining_Processed_Patterns/\"\n",
    "processing_path = os.path.join(processing_folder_dir ,processing_folder)\n",
    "\n",
    "\n",
    "if not os.path.exists(processing_path):\n",
    "    os.makedirs(processing_path)\n",
    "\n",
    "\n",
    "print(\"Processed pattern directory:\", processing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc507d",
   "metadata": {},
   "source": [
    "## Integration using pyFAI module\n",
    "#### pyFAI: https://pyfai.readthedocs.io/en/v2023.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing files and 1D integrating with pyFAI\n",
    "\n",
    "frame_sized = np.zeros((count, 2881, 2880))\n",
    "int_patterns = []\n",
    "a = 0\n",
    "\n",
    "while a < count:\n",
    "    with h5py.File(collection_dir+file_nxs[a], 'r') as dat:\n",
    "        frame = np.array(dat[\"/entry1/pixium_hdf/data\"][()][:]) \n",
    "        frame_sized[a] = frame.reshape(frame.shape[1:])\n",
    "        int_patterns.append(calibration.integrate1d(frame_sized[a], 1000, unit=pyFAI.units.TTH_DEG, radial_range=[1,30], mask=oneD_mask))\n",
    "        a += 1\n",
    "\n",
    "two_theta = int_patterns[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all raw integrated patterns\n",
    "\n",
    "large = []\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.xlim(1, 30)\n",
    "\n",
    "plt.ylabel('Intensity')\n",
    "\n",
    "\n",
    "for i in range(count):\n",
    "    offset = i * 20  # Adjust the offset as needed\n",
    "    plt.plot(two_theta, int_patterns[i][1] + offset, label=format(file_nxs[i]))\n",
    "    large.append(max(int_patterns[i][1]+offset))\n",
    "\n",
    "huge = max(large)\n",
    "#plt.ylim(100,huge+20)\n",
    "plt.legend()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d067fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pattern name to remove any ones displaying no diffraction\n",
    "\n",
    "#remove = [61557 ,\n",
    "        \n",
    "\n",
    "# or remove none    \n",
    "    \n",
    "remove = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files we don't want to process further\n",
    "\n",
    "remove_set = set(remove)\n",
    "\n",
    "filtered_file_list = [file_name for file_name in file_nxs if int(file_name.split('-')[-1].split('.')[0]) not in remove_set]\n",
    "\n",
    "filtered_no = len(filtered_file_list)\n",
    "print(\"Number of filtered files:\", filtered_no)\n",
    "print(\"Filtered file list:\", filtered_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re integrate the chosen files \n",
    "\n",
    "\n",
    "filtered_frame_sized = np.zeros((count, 2881, 2880))\n",
    "filtered_int_patterns = []\n",
    "b = 0\n",
    "\n",
    "for b in range(filtered_no):\n",
    "    with h5py.File(collection_dir+filtered_file_list[b], 'r') as dat:\n",
    "        frame = np.array(dat[\"/entry1/pixium_hdf/data\"][()][:]) \n",
    "        filtered_frame_sized[b] = frame.reshape(frame.shape[1:])\n",
    "        filtered_int_patterns.append(calibration.integrate1d(filtered_frame_sized[b], 1000, unit=pyFAI.units.TTH_DEG, radial_range=[1,30], mask=oneD_mask))\n",
    "       # filtered_int_patterns.append(calibration.integrate1d(filtered_frame_sized[b], 1000, unit=pyFAI.units.TTH_DEG, radial_range=[4,30]))\n",
    "\n",
    "two_theta2 = filtered_int_patterns[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f634c-62ed-4b1c-b8de-2b1adc3d0b30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for too big array issues use this cell \n",
    "# --- Re-integrate the chosen files (memory-safe version) ---\n",
    "\n",
    "filtered_int_patterns = []\n",
    "\n",
    "for b in range(filtered_no):\n",
    "    with h5py.File(collection_dir + filtered_file_list[b], 'r') as dat:\n",
    "        # load frame as float32 to save memory\n",
    "        frame = np.array(dat[\"/entry1/pixium_hdf/data\"][()][:], dtype=np.float32)\n",
    "        \n",
    "        # reshape directly, no giant array preallocation\n",
    "        frame = frame.reshape(frame.shape[1:])\n",
    "\n",
    "        # integrate and append result\n",
    "        filtered_int_patterns.append(\n",
    "            calibration.integrate1d(\n",
    "                frame,\n",
    "                1000,\n",
    "                unit=pyFAI.units.TTH_DEG,\n",
    "                radial_range=[1, 30],\n",
    "                mask=oneD_mask\n",
    "            )\n",
    "        )\n",
    "\n",
    "# extract two_theta axis from first pattern\n",
    "two_theta2 = filtered_int_patterns[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the final files to merge and process\n",
    "\n",
    "large2 = []\n",
    "\n",
    "# Create a new figure\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.xlim(1, 30)\n",
    "\n",
    "plt.ylabel('Intensity')\n",
    "\n",
    "\n",
    "for j in range(filtered_no):\n",
    "    offset = j * 20# Adjust the offset as needed\n",
    "    plt.plot(two_theta2, filtered_int_patterns[j][1] + offset, label=format(filtered_file_list[j]))\n",
    "    large2.append(max(filtered_int_patterns[j][1]+offset))\n",
    "\n",
    "huge2 = max(large2)\n",
    "plt.ylim(10,huge2+20)\n",
    "plt.legend()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summing and averaging the raw patterns\n",
    "\n",
    "raw_intensities = []\n",
    "\n",
    "for k in range(filtered_no):\n",
    "    raw_intensities.append(filtered_int_patterns[k][1])\n",
    "    \n",
    "added = np.sum(raw_intensities, axis=0)\n",
    "averaged_intensities = added/filtered_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e601d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the raw merged pattern\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.xlim(1, 30)\n",
    "plt.ylim(0, 1450)\n",
    "plt.ylabel('Intensity')\n",
    "\n",
    "plt.plot(two_theta2, averaged_intensities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e46119",
   "metadata": {},
   "source": [
    "# Baseline correction \n",
    "\n",
    "### using https://pybaselines.readthedocs.io/en/latest/ mor() baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe650d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline correction set-up\n",
    "\n",
    "x = two_theta2\n",
    "y = averaged_intensities\n",
    "\n",
    "baseline_fitter = Baseline(x_data=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925af6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display baseline correction and edit half_window for a best fit\n",
    "\n",
    "half_window = 2\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.plot(x, y, label='data')\n",
    "plt.plot(x, baseline_fitter.mor(y, half_window=half_window)[0], label=f'half_window={half_window}')\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.xlim(1, 20)\n",
    "#plt.ylim(80, 200)\n",
    "plt.ylabel('Intensity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline correction\n",
    "\n",
    "corrected_data = y - baseline_fitter.mor(y, half_window=half_window)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfaff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all baseline correction stages\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.plot(x, y, label='data')\n",
    "plt.plot(x, baseline_fitter.mor(y, half_window=half_window)[0], label=f'half_window={half_window}')\n",
    "plt.plot(x, (corrected_data*20)+0, label='corrected_baseline')\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.ylabel('Intensity /a.u.')\n",
    "plt.xlim(1, 20)\n",
    "plt.ylim(-5, 200)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(processing_path + run_id + \"_baseline_corr\" + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7c6a9-f777-49f8-833f-df1ca82dc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett addition \n",
    "# Normalise so baseline starts at 0\n",
    "final_corrected = corrected_data - np.min(corrected_data)\n",
    "\n",
    "# --- Save as .xy data file ---\n",
    "# Combine 2Î¸ (x) and intensity (y) into two-column array\n",
    "output_data = np.column_stack((x, final_corrected))\n",
    "\n",
    "# Define output file paths\n",
    "xy_filename = os.path.join(processing_path, f\"{run_id}_final_baselinecorr.xy\")\n",
    "png_filename = os.path.join(processing_path, f\"{run_id}_final_baselinecorr.png\")\n",
    "\n",
    "# Save the .xy file\n",
    "np.savetxt(xy_filename, output_data, fmt=\"%.6f\", header=\"2Theta  Intensity\", comments='')\n",
    "\n",
    "print(f\"Saved XY data: {xy_filename}\")\n",
    "\n",
    "# --- Plot the final corrected pattern ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, final_corrected, color='blue', linewidth=1.2)\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)', fontsize=12)\n",
    "plt.ylabel('Intensity / a.u.', fontsize=12)\n",
    "plt.title( run_id + ' Final Baseline-Corrected PXRD Pattern', fontsize=14)\n",
    "plt.xlim(1, 30)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(png_filename, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved plot: {png_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582038c-2848-4bb4-a351-d8c12ce225d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13faf5-df5b-4ae1-ad7f-872419510d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
