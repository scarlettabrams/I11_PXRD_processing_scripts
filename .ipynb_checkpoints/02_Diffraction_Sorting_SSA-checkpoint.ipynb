{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397a33ea-72b5-45f3-b6db-697c751fe67f",
   "metadata": {},
   "source": [
    "# 02_Diffraction Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec7900-c5a3-48d5-9bda-4c5997a81b26",
   "metadata": {},
   "source": [
    "SSA adapted and developed from original code provided by Beth Galtry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fdb3db-1f3e-4793-99c7-d09c7d6267cd",
   "metadata": {},
   "source": [
    "first step: organise raw diffraction data into usable folders - i.e. by run \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413d564-892c-42ca-bf35-da0705e93ef2",
   "metadata": {},
   "source": [
    "output: sorted list of files to undergo analysis - moves files into diffraction and potential background folders  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ef6ab-a663-4320-81d2-15220039bf43",
   "metadata": {},
   "source": [
    "worth noting these files do not take into consideration calibration file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20554e-e008-432f-b556-169fedb5fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth - unctouched \n",
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab59d4-951a-4a12-8222-d5353685b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth - untouched  \n",
    "#read in all nxs file names in given directory\n",
    "# directory needs \"/\" not \"\\\" and a \"/\" on the end\n",
    "directory = \"D:/I11 Beamtime July/RAW_2D/Run_6_X2_0.5VF/\"\n",
    "nxs_count = 0\n",
    "nxs_files = []\n",
    "\n",
    "# Count the number of .nxs files in directory\n",
    "for files in os.listdir(directory):\n",
    "    filename = os.fsdecode(files)\n",
    "    if filename.endswith(\".nxs\"):\n",
    "        nxs_files.append(filename)\n",
    "        nxs_count += 1\n",
    "print('File count:', nxs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1569037-613a-4cdf-8115-380c7842116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create processing info folder for bar charts and hit rate files later \n",
    "#beth -untouched \n",
    "processing_folder = \"processing_info/\"\n",
    "processing_path = os.path.join(directory,processing_folder)\n",
    "\n",
    "\n",
    "if not os.path.exists(processing_path):\n",
    "    os.makedirs(processing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2689b-1ea1-4894-af44-e5f8e9a12233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett\n",
    "#extract and standardise all raw diffraction frames from.nxs \n",
    "#states file format and checks back that all of the file count from earlier being read correctly. \n",
    "\n",
    "\n",
    "# --- Step 1: Inspect the first file to find the dataset path ---\n",
    "test_file = os.path.join(directory, nxs_files[0])\n",
    "print(\"Inspecting:\", test_file)\n",
    "\n",
    "with h5py.File(test_file, \"r\") as f:\n",
    "    def printname(name):\n",
    "        print(name)\n",
    "    f.visit(printname)        # <-- run this cell, look at the printed tree\n",
    "\n",
    "# Look in the output for the detector dataset, often something like:\n",
    "#    entry1/pixium_hdf/data\n",
    "# or  entry/data/counts\n",
    "# Copy that full path (including the leading /) for use below.\n",
    "\n",
    "\n",
    "# --- Step 2: After you identify the correct dataset path, put it here:\n",
    "dataset_path = \"/entry1/pixium_hdf/data\"     # <-- CHANGE this after inspecting\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Load all frames ---\n",
    "frame_sized = np.zeros((nxs_count, 2881, 2880), dtype=np.float32)\n",
    "\n",
    "for i, fname in enumerate(nxs_files):\n",
    "    file_path = os.path.join(directory, fname)\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        data = f[dataset_path][()]\n",
    "        # adjust reshape if needed\n",
    "        if data.ndim == 3:\n",
    "            # e.g. shape (1, 2881, 2880)\n",
    "            data = data[0]\n",
    "        frame_sized[i] = data\n",
    "\n",
    "print(\"All frames loaded:\", frame_sized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e73b1-121a-4941-ae80-52a65e3827bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth -untouched \n",
    "# read in all frames in directory into a numpy array\n",
    "#reads diffraction image frames and stacks them into a single numpy array for further processing \n",
    "\n",
    "\n",
    "frame_sized = np.zeros((nxs_count, 2881, 2880))  #<<---change values based on pixium dimensions \n",
    "a = 0\n",
    "\n",
    "while a < nxs_count:\n",
    "    with h5py.File(directory+nxs_files[a], 'r') as dat:\n",
    "      nxs_frame = np.array(dat[\"/entry1/pixium_hdf/data\"][()][:]) \n",
    "      frame_sized[a] = nxs_frame.reshape(nxs_frame.shape[1:])\n",
    "      a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8860a8-17e9-4279-ae8a-0c8f8f2de155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett \n",
    "#if error with sizing, run this code - states which files are causing the issue \n",
    "\n",
    "#for a, file in enumerate(nxs_files):\n",
    "    #try:\n",
    "       # with h5py.File(directory + file, 'r') as dat:\n",
    "           # nxs_frame = np.array(dat[\"/entry1/pixium_hdf/data\"][()])\n",
    "           # frame_sized[a] = nxs_frame.reshape(nxs_frame.shape[1:])\n",
    "    #except ValueError as e:\n",
    "       # print(f\"❌ Error with file: {file}\")\n",
    "      #  print(f\"   Array shape: {nxs_frame.shape if 'nxs_frame' in locals() else 'unknown'}\")\n",
    "        #print(f\"   Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da408b45-1603-445d-b5b3-b976fc791c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett - changes made \n",
    "# select value of the \"5th\" (or other, based on pixel_intensity_no) most intense pixel\n",
    "# print those pixel intensities\n",
    "\n",
    "pixel_intensity_no = 5  #<<--- change this depending on data set \n",
    "\n",
    "#calculate correct number of pixels per frame \n",
    "\n",
    "pixels_per_frame = frame_sized[0].size \n",
    "#print (pixels_per_frame)\n",
    "# for 2881X2880 = 8297280\n",
    "\n",
    "# allocate arrays correctly \n",
    "\n",
    "flat_intensities = np.zeros((nxs_count, pixels_per_frame))\n",
    "#flat_intensities = np.zeros((nxs_count, 2075040))\n",
    "pixel_values = np.zeros((nxs_count,))\n",
    "\n",
    "b = 0\n",
    "\n",
    "while b < nxs_count:\n",
    "    flat_intensities[b] = frame_sized[b].flatten()\n",
    "    flat_intensities[b].sort()\n",
    "    pixel_values[b] = flat_intensities[b][-pixel_intensity_no]\n",
    "    b += 1\n",
    "    \n",
    "print(pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7fb11-8689-4365-b268-d5ee4acf9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSA code \n",
    "#used to rename files for plot\n",
    "#adaptations i've added - got rid of hard coded limits for string length from beths code \n",
    "\n",
    "\n",
    "#extract just last folder name from directory path \n",
    "datasets_name = os.path.basename(os.path.normpath(directory))\n",
    "\n",
    "#replace \"/\" with \"-\" incase of subfolders within directory \n",
    "modified_datasets_name = datasets_name.replace(\"/\", \"_\")\n",
    "plot_name = f\"{modified_datasets_name}_{pixel_intensity_no}th_I_plot.png\"\n",
    "plot_directory = os.path.join(directory, plot_name)\n",
    "\n",
    "print (modified_datasets_name)\n",
    "print (plot_name)\n",
    "print (plot_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7dafa3-da78-4c7d-b267-2cdf6235182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett code \n",
    "# Optional: load a detector mask\n",
    "# Replace the path with your mask file if you have one\n",
    "# mask_array should be a 2D array, 1 = good pixel, 0 = bad pixel\n",
    "\n",
    "# Path to the directory containing the mask\n",
    "mask_directory = \"D:/I11 Beamtime July/\"  # replace with your folder path\n",
    "mask_filename = \"calib_kap_mask.npy\"                  # or mask.png, mask.tif, etc.\n",
    "mask_path = os.path.join(mask_directory, mask_filename)\n",
    "\n",
    "# Initialize mask_array\n",
    "mask_array = None\n",
    "\n",
    "# Check if mask file exists\n",
    "if os.path.exists(mask_path):\n",
    "    print(f\"Loading mask from: {mask_path}\")\n",
    "    \n",
    "    # Determine file type by extension\n",
    "    ext = os.path.splitext(mask_filename)[1].lower()\n",
    "    \n",
    "    if ext == \".npy\":\n",
    "        mask_array = np.load(mask_path)\n",
    "    elif ext in [\".png\", \".tif\", \".tiff\"]:\n",
    "        mask_image = Image.open(mask_path)\n",
    "        mask_array = np.array(mask_image)\n",
    "        mask_array = (mask_array > 0).astype(int)  # ensure binary mask\n",
    "    else:\n",
    "        print(\"Mask file type not recognized. Please use .npy, .png, or .tif\")\n",
    "    \n",
    "    print(\"Mask loaded. Shape:\", mask_array.shape)\n",
    "    print(\"Unique values in mask:\", np.unique(mask_array))\n",
    "else:\n",
    "    print(\"No mask file found. Proceeding without a mask.\")\n",
    "    mask_array = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297720c-9ce0-4b96-933b-3aca14221618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarlett code -pixel intensities and masking \n",
    "# define robust nth pixxel function -- n can be altered \n",
    "def robust_nth_pixel(frame, n=5, percentile_cut=99.9, mask=None):\n",
    "    \"\"\"\n",
    "    Returns the nth most intense pixel in a frame, ignoring extreme outliers.\n",
    "    \n",
    "    frame : 2D numpy array\n",
    "        Single detector frame\n",
    "    n : int\n",
    "        Which brightest pixel to return\n",
    "    percentile_cut : float\n",
    "        Percentile above which pixels are ignored (to remove cosmic rays)\n",
    "    mask : 2D numpy array, optional\n",
    "        Boolean or 0/1 mask to ignore known bad pixels\n",
    "    \"\"\"\n",
    "    pixels = frame.ravel()\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        pixels = pixels[mask.ravel() > 0]  # only include valid pixels\n",
    "\n",
    "    # Remove extreme high pixels\n",
    "    threshold = np.percentile(pixels, percentile_cut)\n",
    "    pixels_clipped = pixels[pixels < threshold]\n",
    "    \n",
    "    # Sort descending\n",
    "    sorted_pixels = np.sort(pixels_clipped)[::-1]\n",
    "    \n",
    "    # Return nth largest\n",
    "    return sorted_pixels[n-1]  # 0-indexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7987b-6281-4570-85b6-47933453db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett code adaptations\n",
    "#pixel intenisties and masking \n",
    "# pixel_intensity_no = which brightest pixel you want to track, e.g., 5\n",
    "pixel_intensity_no = 5\n",
    "\n",
    "# frame_sized should already be loaded as a 3D array: (frames, height, width)\n",
    "pixel_values = [\n",
    "    robust_nth_pixel(frame_sized[i], n=pixel_intensity_no, mask=mask_array) \n",
    "    for i in range(len(frame_sized))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a83ca-d3a2-4447-9d02-fe47072916e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett code adaptations \n",
    "#plot bar chart as a function of intensity \n",
    "plt.rcParams[\"figure.figsize\"] = 18, 10\n",
    "plt.title(datasets_name + \" Intensity plot\", fontsize=24)\n",
    "plt.bar(nxs_files, pixel_values, width=0.8, align='center')\n",
    "plt.xticks(range(len(nxs_files)), nxs_files, rotation='vertical')\n",
    "plt.xlabel('Sample No.', fontsize=15)\n",
    "plt.ylabel('Intensity of '+str(pixel_intensity_no)+'th most intense pixel', fontsize=15)\n",
    "\n",
    "# Autoscale around data\n",
    "plt.ylim(min(pixel_values) * 0.95, max(pixel_values) * 1.05)\n",
    "\n",
    "plt.savefig(processing_path + plot_name)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de21f7c-0803-4264-92f4-b79cfc6525f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth code \n",
    "# read in hdf file names\n",
    "hdf_count = 0\n",
    "hdf_files = []\n",
    "\n",
    "for files2 in os.listdir(directory):\n",
    "    filename2 = os.fsdecode(files2)\n",
    "    if filename2.endswith(\".hdf\"):\n",
    "        hdf_files.append(filename2)\n",
    "        hdf_count += 1\n",
    "\n",
    "# Each row will be [nxs_file, pixel_value, hdf_file]\n",
    "names_values = np.array(list(zip(nxs_files, pixel_values, hdf_files)))\n",
    "print (names_values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b1591-cf89-4bd1-bcd7-308fb71ba3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett code\n",
    "#value for spot threshold to be used in the next cell\n",
    "\n",
    "# define overlay function\n",
    "def overlay_mask(frame, mask, alpha=0.5):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(frame, cmap='gray', vmax=np.percentile(frame,99))\n",
    "    plt.imshow(mask, cmap='Reds', alpha=alpha)\n",
    "    plt.colorbar(label='Intensity')\n",
    "    plt.title('Frame with threshold overlay')\n",
    "    plt.show()\n",
    "\n",
    "# pick a frame to test\n",
    "frame_idx = 0\n",
    "frame = frame_sized[frame_idx]\n",
    "\n",
    "# compute robust threshold: median + 5*sigma_est\n",
    "median = np.median(frame)\n",
    "mad = np.median(np.abs(frame - median))  # median absolute deviation\n",
    "sigma_est = 1.4826 * mad                 # approximate sigma\n",
    "cand_median_plus = median + 5 * sigma_est  # robust threshold\n",
    "\n",
    "# create mask using this threshold\n",
    "mask = frame > cand_median_plus\n",
    "\n",
    "# visualize overlay\n",
    "overlay_mask(frame, mask)\n",
    "\n",
    "print(\"Threshold used:\", cand_median_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c807ef7-6dc4-4b17-852f-7ca81a89006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth code \n",
    "# threshold potential backgrounds/diffraction frames with spots_threshold\n",
    "# list the number of potential backgrounds and names of these\n",
    "\n",
    "# change spots threshold to desired cut off for diffraction/background\n",
    "\n",
    "spots_threshold = 550\n",
    "\n",
    "diffraction_frames = []\n",
    "diffraction_hdf = []\n",
    "background_frames = []\n",
    "background_hdf = []\n",
    "\n",
    "c = 0\n",
    "while c < nxs_count:\n",
    "    # pixel value is in column 1\n",
    "    if float(names_values[c, 1]) > spots_threshold:\n",
    "        diffraction_frames.append(names_values[c, 0])  # nxs filename\n",
    "        diffraction_hdf.append(names_values[c, 2])     # hdf filename\n",
    "    else:\n",
    "        background_frames.append(names_values[c, 0])   # nxs filename\n",
    "        background_hdf.append(names_values[c, 2])      # hdf filename\n",
    "\n",
    "    # increment once after both branches\n",
    "    c += 1\n",
    "\n",
    "print('Number of potential background frames:', len(background_frames))\n",
    "background_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3fc76-bc91-4720-837b-698a70fdd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarlett \n",
    "#set up backgrounds folder \n",
    "\n",
    "backgrounds_folder = \"Potential backgrounds/\"\n",
    "bg_path = os.path.join(directory, backgrounds_folder)\n",
    "os.makedirs(bg_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd18ba-2e6f-4dff-b633-da4d71dae03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett \n",
    "#function to get numeric suffix\n",
    "\n",
    "import re\n",
    "\n",
    "def get_last_three_digits(filename):\n",
    "    \"\"\"\n",
    "    Extract the last three consecutive digits from the filename (before extension)\n",
    "    Example: 'run001_frame005.nxs' -> '005'\n",
    "    \"\"\"\n",
    "    base = os.path.splitext(filename)[0]  # remove extension\n",
    "    match = re.findall(r'(\\d{3})', base)  # find all groups of 3 digits\n",
    "    return match[-1] if match else None   # take the last one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a558a-fbe5-4329-8014-10ecaebcd9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett\n",
    "#matching hdf to nxs and mving to background folder \n",
    "\n",
    "for nxs_file in background_frames:\n",
    "    # Move the .nxs file\n",
    "    src_nxs = os.path.join(directory, nxs_file)\n",
    "    dst_nxs = os.path.join(bg_path, nxs_file)\n",
    "    if os.path.exists(src_nxs):\n",
    "        os.replace(src_nxs, dst_nxs)\n",
    "    \n",
    "    # Extract last three digits from the nxs file\n",
    "    nxs_id = get_last_three_digits(nxs_file)\n",
    "    \n",
    "    # Find any hdf file containing the same last three digits\n",
    "    matching_hdf = [f for f in background_hdf if get_last_three_digits(f) == nxs_id]\n",
    "    \n",
    "    # Move matched hdf file(s)\n",
    "    for hdf_file in matching_hdf:\n",
    "        src_hdf = os.path.join(directory, hdf_file)\n",
    "        dst_hdf = os.path.join(bg_path, hdf_file)\n",
    "        if os.path.exists(src_hdf):\n",
    "            os.replace(src_hdf, dst_hdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec422c-be98-4d20-889a-3df74b0287f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett \n",
    "# List files in the backgrounds folder\n",
    "bg_files = os.listdir(bg_path)\n",
    "\n",
    "# Count .nxs and .hdf files\n",
    "nxs_count = len([f for f in bg_files if f.endswith('.nxs')])\n",
    "hdf_count = len([f for f in bg_files if f.endswith('.hdf')])\n",
    "\n",
    "print(f\"Total files in '{backgrounds_folder}': {len(bg_files)}\")\n",
    "print(f\" - .nxs files: {nxs_count}\")\n",
    "print(f\" - .hdf files: {hdf_count}\")\n",
    "\n",
    "# Optionally, print a few filenames for confirmation\n",
    "print(\"\\nSample of moved files:\")\n",
    "print(bg_files[:10])  # prints first 10 filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ed5bf-9d81-405e-a6f2-ba3d620f1f4f",
   "metadata": {},
   "source": [
    "# Check in DAWN - manually sort into correct folders "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cfdc6-6269-43ec-8522-c8ea20e73c5f",
   "metadata": {},
   "source": [
    "from the previous code - the frames should already by placed in the correct folder if it is a background - but double checking is wise to make sure no diffraction is lost and no background is being analysed as having data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a9796-c388-40b9-a532-d4ebe6ac28e4",
   "metadata": {},
   "source": [
    "DAWN download: https://dawnsci.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bdb7a-e479-4986-8658-fd5af0d50801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth code \n",
    "diff_count = 0\n",
    "\n",
    "for files in os.listdir(directory):\n",
    "    filename = os.fsdecode(files)\n",
    "    if filename.endswith(\".nxs\"):\n",
    "        diff_count += 1\n",
    "print('Sorted diffraction frames:', diff_count)\n",
    "\n",
    "\n",
    "bg_count = 0\n",
    "\n",
    "for files in os.listdir(bg_path):\n",
    "    filename = os.fsdecode(files)\n",
    "    if filename.endswith(\".nxs\"):\n",
    "        bg_count += 1\n",
    "print('Sorted background frames:', bg_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12bb50-4867-43ca-b09c-8909d9d9937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Hit rate calculation\n",
    "# ------------------------------\n",
    "\n",
    "# Total number of sorted frames\n",
    "total_sorted = diff_count + bg_count\n",
    "\n",
    "if total_sorted > 0:\n",
    "    hit_rate = round((diff_count / total_sorted) * 100, 1)\n",
    "else:\n",
    "    hit_rate = 0  # avoid division by zero\n",
    "\n",
    "hit_rate_text = f\"{hit_rate}%\"\n",
    "print(f\"Hit rate (diffraction frames as % of total sorted frames): {hit_rate_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be7dd0-d090-41f2-8134-9645fe83f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth code\n",
    "output_file_path = processing_path + modified_datasets_name+ \"_hit_rates.txt\"\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(f\"Datasets location: {directory}\\n\\n\")\n",
    "    file.write(f\"Total frames:   {nxs_count}\\n\\n\")\n",
    "    file.write(f\"Pixel intensity number: {pixel_intensity_no}\\n\")\n",
    "    file.write(f\"Spots threshold: {spots_threshold}\\n\")\n",
    "    file.write(f\"Number of thresholded background frames: {str(len(background_frames))}\\n\\n\")\n",
    "    file.write(f\"Frames with diffraction:    {diff_count} \\n\")\n",
    "    file.write(f\"Sorted background frames:    {bg_count} \\n\\n\")\n",
    "    file.write(f\"Hit rate:    {hit_rate_text} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb20a7-ec78-4753-8ca1-5424ce32de3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
