{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda25d24",
   "metadata": {},
   "source": [
    "# 04A_Pre_Merging_Baselining_SSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e3c93-2d69-406e-abf6-ad051a16c191",
   "metadata": {},
   "source": [
    "### This script is updated and developed off of the pybaselineCorrected_merged.ipynb from Beth Galtry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b0579",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c987ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import pandas as pd        \n",
    "import math\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install pyFAI\n",
    "import pyFAI\n",
    "from pyFAI.gui import jupyter\n",
    "\n",
    "!{sys.executable} -m pip install pybaselines\n",
    "from pybaselines import Baseline\n",
    "from pybaselines.utils import gaussian\n",
    "\n",
    "pi = math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524449d",
   "metadata": {},
   "source": [
    "## Specify diffraction frame to read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth \n",
    "# data file from I11 in form i11-1-61284.nxs, adjust depending on data name and format\n",
    "\n",
    "\n",
    "data_file_no = \"107655\"\n",
    "data_dir = \"D:/I11 Beamtime July/RAW_2D/Run_3_X3_0.5VF\"  #\"C:/path/to/your/data/file/\"\n",
    "\n",
    "data_file = \"i11-1-\" + data_file_no + \".nxs\"\n",
    "\n",
    "file_path = os.path.join(data_dir, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth\n",
    "# creation of folder to store processed information\n",
    "processing_folder = \"04A_Pre_Merging_Baselining/individual_frame_patterns/\"\n",
    "processing_path = os.path.join(data_dir,processing_folder)\n",
    "\n",
    "\n",
    "if not os.path.exists(processing_path):\n",
    "    os.makedirs(processing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth\n",
    "with h5py.File(file_path, 'r') as dat:\n",
    "    \n",
    "    #load in as (1, 1441, 1440) shape array\n",
    "    myData = np.array(dat[\"/entry1/pixium_hdf/data\"][()][:]) \n",
    "    \n",
    "    #extract only (1441,1440)\n",
    "    diff_frame = myData.reshape(myData.shape[1:])\n",
    "    \n",
    "total_intensity = np.sum(diff_frame)\n",
    "\n",
    "diff_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beth \n",
    "# visualise chosen diffraction frame\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=14,14\n",
    "plt.title(data_file, fontsize=24)\n",
    "plt.imshow(diff_frame, cmap='gray', vmin=0, vmax=300)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4a38e",
   "metadata": {},
   "source": [
    "# Load calibration file\n",
    "\n",
    "calibrated using pyFAI-calib2 tool\n",
    "\n",
    "pyFAI: https://pyfai.readthedocs.io/en/v2023.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the calibration .poni file \n",
    "calibration = pyFAI.load(\"D:/I11 Beamtime July/calib_fep.poni\")   #('C:/poni/file/location/calibration.poni')\n",
    "calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mask for detector frame\n",
    "oneD_mask = np.load(\"D:/I11 Beamtime July/calib_fep_mask.npy\")    #(\"C:/mask/file/location/mask.npy\")\n",
    "oneD_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab5072",
   "metadata": {},
   "source": [
    "## Integration using pyFAI module\n",
    "#### pyFAI: https://pyfai.readthedocs.io/en/v2023.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48967410-d199-4804-abc1-2343079636f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_pattern_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "threshold_pattern_name = threshold_pattern_name.replace(\"i11-1-\", \"\") + \"_baselineCorrected\"\n",
    "\n",
    "print(threshold_pattern_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett adaptation\n",
    "\n",
    "#integrate the 2D pattern into a 1D frame \n",
    "oneD_integrated_plot = calibration.integrate1d(\n",
    "    diff_frame,\n",
    "    1000,\n",
    "    unit=pyFAI.units.TTH_DEG,\n",
    "    radial_range=[0, 30],\n",
    "    mask=oneD_mask\n",
    ")\n",
    "\n",
    "# Plot\n",
    "jupyter.plot1d(oneD_integrated_plot)\n",
    "plt.title(threshold_pattern_name, fontsize=15)\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.xlim(4, 30)\n",
    "#plt.ylim(-0.1, 500)\n",
    "plt.ylabel('Intensity')\n",
    "#plt.savefig(processing_path + threshold_pattern_name +\"_1D_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d626971",
   "metadata": {},
   "source": [
    "# Baseline correction \n",
    "\n",
    "### using https://pybaselines.readthedocs.io/en/latest/ mor() baseline correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intensity_values = oneD_integrated_plot[1]\n",
    "two_theta = oneD_integrated_plot[0]\n",
    "x = two_theta\n",
    "y = intensity_values\n",
    "\n",
    "baseline_fitter = Baseline(x_data=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oneD_integrated_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ce610-1e48-4e1e-95e1-83ab9dd06430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scarlett\n",
    "#Determine Half window value :)\n",
    "# typically PXRD Data uses the range of 5-15 \n",
    "# You want the baseline to follow the general background trend without cutting into any true diffraction peaks.\n",
    "plt.figure(figsize=(10,6))\n",
    "for hw in [3, 7, 10, 15]:\n",
    "    baseline = baseline_fitter.mor(y, half_window=hw)[0]\n",
    "    plt.plot(x, baseline, label=f'half_window={hw}')\n",
    "plt.plot(x, y, 'k--', alpha=0.3, label='data')\n",
    "plt.legend()\n",
    "plt.xlabel('2θ (°)')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Effect of half_window on baseline shape')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf327a7-6115-4b5f-af95-0d3d4a043781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scarlett \n",
    "#automated estimate of suitable half window value \n",
    "# Calculate step size in 2θ\n",
    "step_size = np.mean(np.diff(x))  # degrees per data point\n",
    "\n",
    "# Estimate how many data points correspond to ~0.3–0.5° of 2θ background curvature\n",
    "# (adjust this range if your background varies faster or slower)\n",
    "background_scale_deg = 0.4  # typical slow-varying background over ~0.4°\n",
    "half_window_estimate = int(background_scale_deg / step_size / 2)\n",
    "\n",
    "# Ensure it's an odd, reasonable value (avoid too small or too large)\n",
    "half_window = max(3, min(half_window_estimate, 25))\n",
    "\n",
    "print(f\"Estimated half_window = {half_window} (based on step size {step_size:.4f}°)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f7bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline correction, change half_window valuue to best fit dataset\n",
    "\n",
    "half_window = 6\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label='data')\n",
    "plt.plot(x, baseline_fitter.mor(y, half_window=half_window)[0], label=f'half_window={half_window}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae11d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline correction\n",
    "corrected_data = y - baseline_fitter.mor(y, half_window=half_window)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33281e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting of baseline corrected pattern against baseline correction parameters\n",
    "\n",
    "twoD_pattern_name_baseline_corr = data_file_no +\"_baseline_corr_half_window_\" + str(half_window)\n",
    "\n",
    "baseline_corr_name = data_file_no + \"half_window_\" + str(half_window) + \"_baseline\"\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label='data')\n",
    "plt.plot(x, baseline_fitter.mor(y, half_window=half_window)[0], label=f'half_window={half_window}')\n",
    "plt.plot(x, corrected_data, label='corrected_baseline')\n",
    "plt.title(baseline_corr_name, fontsize=15)\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.ylabel('Intensity')\n",
    "plt.xlim(4, 20)\n",
    "plt.legend()\n",
    "plt.savefig(processing_path + twoD_pattern_name_baseline_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d39b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final pattern\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, corrected_data, label= 'final_pattern')\n",
    "plt.title(twoD_pattern_name_baseline_corr, fontsize=15)\n",
    "plt.xlabel('$2\\\\theta$ ($^{o}$)')\n",
    "plt.ylabel('Intensity')\n",
    "plt.xlim(1, 30)\n",
    "plt.ylim(-0.1, 900)\n",
    "plt.savefig(processing_path + twoD_pattern_name_baseline_corr + \"_final_pattern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e57b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting final pattern as .xy data\n",
    "\n",
    "np.savetxt(processing_path+twoD_pattern_name_baseline_corr+ \".xy\", np.c_[x, corrected_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d155b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f5910-db59-4817-9d7a-57b5ded393e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
